VOC 및 COCO 모델은 공식 다크넷 레포의 정량화된 가중치에 해당한다. 얼굴 검출기는 일반 컨볼루션 대신 깊이 있게 분리 가능한 컨볼루션을 사용하여 훨씬 더 빠른 예측과 작은 모델 크기를 제공하며, 이는 모바일 장치의 물체 감지에도 매우 적합하다. 나는 얼굴 탐지 모델을 처음부터 훈련시켰다. 자신의 데이터 세트에 대해 이러한 모델을 교육하려면 자신의 개체 디텍터 교육 섹션을 살펴보십시오!

만약 당신이 당신 자신의 객체 검출기를 훈련시키고 싶다면, 나는 분리 가능한 컨볼루션으로 모델을 훈련시키는 것을 제안할 것이다. 왜냐하면 그것은 훨씬 더 빠른 추론 시간을 허용하고 훈련 과정이 훨씬 더 빨리 수렴될 것이기 때문이다. 훈련할 매개 변수가 훨씬 적기 때문이다.

다중 클래스 디텍터를 교육하려면 개체 디텍터를 교육하는 클래스에 따라 상당한 시간이 걸립니다. 그러나 단일 클래스 감지기를 훈련시키는 것은 단지 몇 시간 동안 훈련한 후에 이미 꽤 좋은 결과를 얻을 수 있다.

교육 세트의 각 이미지에 대해 해당 이미지에 위치한 각 개체 인스턴스의 경계 상자 및 클래스 레이블을 포함하는 해당 json 파일을 생성해야 합니다. 경계 상자 치수는 영상 치수에 상대적이어야 합니다.

폭과 높이가 400px인 이미지를 생각해 보십시오. 이 이미지는 x = 50px, y = 100px(왼쪽 상단 모서리)의 경계 상자에 의해 확장되며 폭은 200px, 높이는 100px입니다. 해당 json 파일은 다음과 같이 표시되어야 합니다(참고로 해당 이미지에 대한 모든 경계 상자의 배열임).

디텍터를 교육하기 전에 교육 세트 위에 5개의 앵커 상자를 계산하려고 합니다. 앵커 박스는 기본적으로 모양 {x:boxWidth / 32, y: boxHeight / 32 }의 객체이며, 여기서 x와 y는 그리드 셀 크기(32px)에 상대적인 앵커 박스 크기이다.

5개의 앵커 상자를 결정하려면 교육 세트의 각 접지 진실 상자의 폭과 높이에 걸쳐 5개의 군집을 갖는 k평균 군집화를 수행하려고 합니다. kmeans 클러스터링에 사용할 수 있는 옵션이 많이 있을 것입니다. 하지만 곧 스크립트를 제공할 것입니다.

Yolo loss 함수는 좌표, 객체, 클래스 및 객체 손실 없음의 합계를 계산한다. 위에서 언급한 대로 구성 파일에서 해당 척도 파라미터를 조정하여 전체 손실에 기여하는 각 손실 기간의 가중치를 조정할 수 있습니다.

무객체 손실 항은 그리드에 있는 모든 상자 앵커의 경계 상자 점수에 불이익을 주며, 여기에는 해당 접지 실측 경계 상자가 없다. 즉, 해당 위치에 관심 대상이 없는 경우 최적으로 점수 0을 예측해야 합니다.

반면에 객체, 클래스 및 좌표 손실 항은 실제 경계 상자가 있는 각 앵커 위치에서 예측의 정확도를 의미한다. 좌표 손실은 단순히 예측 경계 상자 좌표와 접지 진실 상자 좌표 간의 차이를 불이익을 주고, 객체 손실은 상자 IOU에 대한 예측 신뢰 점수의 차이를 불이익을 준다.

학급 손실은 예상 점수의 신뢰도 점수를 벌한다. 단일 클래스 개체 디텍터를 교육하는 경우 클래스 손실은 항상 0이기 때문에 해당 매개 변수를 무시할 수 있습니다.

PS: 위에 표시된 구성 예제의 기본값을 사용하면 됩니다.

처음부터 모델을 훈련시키려면, 처음부터 약간의 무게가 필요하다. 간단히 열어보세요.Weights.html은 브라우저의 repo의 /train 폴더에 있습니다. 클래스 수를 입력하고 저장을 누른 다음 저장된 파일을 초기 체크포인트 무게 파일로 사용합니다.


